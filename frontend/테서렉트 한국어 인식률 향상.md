# **테서렉트(Tesseract) OCR 한국어 인식률 최적화를 위한 심층 기술 분석 및 파이프라인 구축 전략**

## **1\. 서론: 광학 문자 인식의 진화와 한국어 처리의 기술적 난제**

디지털 전환(Digital Transformation)의 가속화 속에서 아날로그 문서를 디지털 데이터로 변환하는 광학 문자 인식(OCR, Optical Character Recognition) 기술은 단순한 편의 도구를 넘어 비즈니스 프로세스 자동화(RPA)의 핵심 엔진으로 자리 잡았다. 이 중 구글(Google)이 유지 보수하고 있는 오픈 소스 엔진인 테서렉트(Tesseract)는 그 범용성과 접근성으로 인해 학계와 산업계 전반에서 표준적인 도구로 활용되고 있다. 특히 버전 4.0 이후 도입된 순환 신경망(RNN)의 일종인 LSTM(Long Short-Term Memory) 기반 아키텍처는 문맥 정보를 활용한 시퀀스 인식을 가능케 하여 인식률의 비약적인 향상을 이끌어냈다.

그러나 이러한 기술적 진보에도 불구하고, 한국어(Hangul)는 그 독특한 자형적 구조와 조합 원리로 인해 OCR 엔진에게 여전히 까다로운 기술적 도전 과제를 제시한다. 라틴(Latin) 계열의 문자가 선형적으로 나열되는 1차원적 구조를 가지는 반면, 한국어는 초성, 중성, 종성이 결합하여 하나의 음절(Syllable)을 형성하는 2차원적인 결합 구조를 가진다. 이는 11,172자에 달하는 방대한 완성형 유니코드 조합을 생성하며, 각 글자의 획 밀도가 높고 복잡하여 저해상도 이미지나 노이즈가 섞인 환경에서는 획 뭉침이나 소실이 빈번하게 발생한다. 또한, 조사와 어미가 발달한 교착어(Agglutinative Language)의 특성상 단어의 형태 변화가 다양하여 단순한 사전 기반의 후처리만으로는 오류를 완벽히 수정하기 어렵다.

본 연구 보고서는 테서렉트 OCR을 사용하여 한국어 문서 및 이미지의 인식률을 극대화하기 위한 "최고의 방법"을 규명하는 것을 목적으로 한다. 이를 위해 단순히 엔진의 옵션을 조절하는 수준을 넘어, 컴퓨터 비전(Computer Vision) 기반의 이미지 전처리(Pre-processing), 테서렉트 엔진 내부 아키텍처의 이해에 기반한 하이퍼파라미터 튜닝, 사용자 데이터 맞춤형 파인튜닝(Fine-tuning) 방법론, 그리고 자연어 처리(NLP) 기술을 접목한 후처리(Post-processing) 파이프라인까지 포괄하는 전방위적인 최적화 전략을 제시한다. 또한, 최근 부상하고 있는 PaddleOCR, EasyOCR 등 딥러닝 기반의 경쟁 엔진들과의 벤치마크 비교를 통해 테서렉트의 위상과 한계를 명확히 하고, 상황에 따른 최적의 하이브리드 전략을 도출한다.

## ---

**2\. 입력 데이터의 물리학: 이미지 전처리(Pre-processing) 전략**

OCR 프로세스의 성능은 입력되는 이미지의 품질에 절대적으로 의존한다. "Garbage In, Garbage Out"이라는 데이터 과학의 격언은 OCR 분야에서 불변의 진리이다. 테서렉트 엔진은 본질적으로 흑백(Binary) 이미지 상의 픽셀 패턴을 분석하여 문자를 추론하기 때문에, 엔진에 이미지가 전달되기 전 단계에서의 픽셀 단위 최적화가 최종 인식률(CER, Character Error Rate)을 결정짓는 가장 중요한 변수가 된다. 특히 한국어와 같이 획이 복잡하고 밀도가 높은 문자의 경우, 전처리 단계에서의 미세한 조정이 인식 성공 여부를 가르는 결정적 요인이 된다.

### **2.1 해상도 및 샘플링 밀도의 최적화**

디지털 이미지에서 문자의 가독성은 픽셀 밀도, 즉 DPI(Dots Per Inch)에 의해 결정된다. 테서렉트 엔진은 기본적으로 300 DPI 이상의 해상도에서 텍스트의 특징(Feature)을 가장 잘 추출하도록 설계되었다. 1 및 2의 연구 결과에 따르면, 이미지 해상도를 웹 표준인 72 DPI에서 인쇄 표준인 300 DPI로 향상시켰을 때 OCR 정확도가 최대 30\~50%까지 개선될 수 있음이 보고되었다. 이는 낮은 해상도에서는 한국어의 '이'와 '아'를 구분하는 짧은 획이나, '은'과 '는'의 미세한 자형 차이가 픽셀 뭉개짐(Aliasing) 현상으로 인해 소실되기 때문이다.

특히 폰트 크기가 10pt 미만인 작은 텍스트나 고문서의 경우, 300 DPI조차 부족할 수 있다. 이러한 경우 400\~600 DPI까지 업스케일링(Upscaling)하는 것이 권장된다. 그러나 무조건적인 고해상도가 정답은 아니다. 해상도가 지나치게 높으면 처리 속도가 기하급수적으로 느려질 뿐만 아니라, 종이의 질감이나 미세한 먼지 같은 고주파 노이즈까지 선명하게 캡처되어 오히려 인식률을 저해할 수 있다. 따라서 원본 이미지의 상태를 분석하여 폰트의 x-height(소문자 x의 높이, 한국어에서는 'ㅁ' 등의 높이)가 최소 30\~33픽셀 이상이 되도록 리사이징하는 것이 가장 이상적인 기준이다. 2

리사이징 알고리즘의 선택 또한 중요하다. 단순한 최근방 이웃(Nearest Neighbor) 보간법은 계단 현상을 악화시키므로 피해야 하며, Bicubic 또는 Lanczos 보간법을 사용하여 엣지(Edge)의 부드러움을 유지하면서도 선명도를 확보해야 한다. 최근에는 SRGAN(Super-Resolution Generative Adversarial Networks)과 같은 딥러닝 기반의 초해상도 기술을 적용하여 깨진 글자의 획을 복원하는 연구도 진행되고 있으나, 실시간 처리가 필요한 환경에서는 연산 비용 문제로 인해 Bicubic 보간법이 여전히 표준으로 사용된다. 3

### **2.2 이진화(Binarization) 알고리즘의 심층 분석**

OCR 엔진은 기본적으로 그레이스케일이나 컬러 이미지가 아닌, 흑과 백으로만 이루어진 이진 이미지를 처리한다. 이진화는 배경과 전경(텍스트)을 분리하는 가장 핵심적인 단계로, 적절한 임계값(Threshold)을 설정하는 것이 관건이다.

가장 널리 사용되는 \*\*Otsu의 이진화(Otsu's Binarization)\*\*는 이미지 전체의 히스토그램을 분석하여 두 개의 클래스(배경과 전경) 간의 분산을 최대화하는 임계값을 자동으로 찾아낸다. 이 방식은 조명이 균일한 스캔 문서에서는 탁월한 성능을 발휘한다. 그러나 그림자가 지거나 조명이 불균일한 '자연 장면(Scene Text)' 이미지나 구겨진 영수증 이미지에서는 치명적인 한계를 보인다. 그림자 영역이 임계값보다 어두워 검은 덩어리로 인식되거나, 밝은 조명을 받은 글자가 배경으로 날아가는 현상이 발생하기 때문이다.

이러한 문제를 해결하기 위해 **적응형 임계값(Adaptive Thresholding)** 기법이 필수적으로 도입되어야 한다. 4 및 5의 사례는 적응형 임계값의 중요성을 잘 보여준다. 이 방식은 이미지 전체에 단일 임계값을 적용하는 대신, 픽셀 주변의 국소 영역(Local Neighborhood)을 분석하여 해당 영역만의 임계값을 계산한다. 이를 통해 그림자가 진 영역에서도 글자의 윤곽을 선명하게 추출할 수 있다. 특히 한국어 문서에서는 cv2.ADAPTIVE\_THRESH\_GAUSSIAN\_C 방식을 적용하는 것이 유리한데, 이는 주변 픽셀의 가중 평균을 사용하여 노이즈에 강건하면서도 글자의 획을 부드럽게 보존하기 때문이다. 단순 평균(Mean) 방식은 노이즈에 민감하여 글자 주변에 자잘한 점들이 생길 수 있다.

### **2.3 형태학적 연산(Morphological Operations)을 통한 획 보정**

한국어 OCR에서 가장 빈번하게 발생하는 오류 유형은 획이 끊어져(Broken characters) 자음과 모음이 분리되거나, 반대로 획이 뭉쳐서(Merging) 다른 글자로 오인되는 현상이다. 이를 물리적으로 보정하기 위해 OpenCV의 형태학적 연산을 전략적으로 사용해야 한다. 6

| 연산 기법 | 작동 원리 및 한국어 최적화 전략 | OpenCV 구현 |
| :---- | :---- | :---- |
| **침식 (Erosion)** | 객체(글자)의 경계를 깎아내는 연산이다. 굵은 폰트(Bold)가 뭉쳐서 'ㅁ'이 검은 사각형으로 인식되거나 '롤'의 'ㄹ' 획이 붙어버리는 경우에 효과적이다. | cv2.erode() |
| **팽창 (Dilation)** | 객체의 경계를 확장하여 살을 붙이는 연산이다. 얇은 폰트나 저해상도 이미지에서 획이 끊어질 때, 이를 연결하여 온전한 자형을 복원한다. 한국어의 경우 모음 'ㅣ'가 사라지거나 자음과 분리되는 것을 방지하는 데 필수적이다. | cv2.dilate() |
| **열림 (Opening)** | 침식 연산 후 팽창 연산을 수행한다. 글자의 형태는 유지하면서 배경의 미세한 노이즈(Salt noise)를 제거한다. | cv2.morphologyEx(..., cv2.MORPH\_OPEN) |
| **닫힘 (Closing)** | 팽창 연산 후 침식 연산을 수행한다. 글자 내부의 작은 구멍(Pepper noise)을 메우거나, 끊어진 획을 연결하는 강력한 수단이다. | cv2.morphologyEx(..., cv2.MORPH\_CLOSE) |

한국어 맞춤형 커널(Kernel) 전략:  
형태학적 연산의 효과는 커널의 크기와 모양에 의해 결정된다. 한국어는 자획의 밀도가 높고 획 간 간격이 좁으므로, 지나치게 큰 커널을 사용하면 글자가 뭉개질 수 있다. 일반적으로 (3, 3\) 또는 (2, 2\) 크기의 직사각형 커널이 안전한 선택이다. 그러나 특정 상황에서는 비대칭 커널이 유용할 수 있다. 예를 들어, 가로획이 얇아서 자주 끊어지는 명조체 폰트의 경우, 가로 길이가 긴 (3, 1\) 커널을 사용하여 가로획만 선택적으로 보강할 수 있다. 반대로 세로획을 강조하고 싶다면 (1, 3\) 커널을 사용한다. 9은 이러한 커널 튜닝이 단순한 시행착오가 아니라, 대상 문서의 폰트 특성에 맞춘 공학적 접근이어야 함을 시사한다.

### **2.4 기하학적 보정: 기울기 및 투시 변환**

테서렉트의 텍스트 라인 세그먼테이션(Line Segmentation) 알고리즘은 텍스트가 수평으로 정렬되어 있다는 가정을 전제로 한다. 따라서 문서가 스캔 과정에서 약간만 회전되어도(Skew), 엔진은 텍스트 라인을 제대로 검출하지 못하고 인식률이 급락한다.

Deskewing (기울기 보정):  
입력 이미지의 텍스트 방향을 분석하여 수평을 맞추는 과정은 필수적이다. 간단하게는 pytesseract의 OSD(Orientation and Script Detection) 모드를 사용하여 페이지의 회전 각도를 얻을 수 있다. 그러나 OSD는 90도 단위의 회전만 감지하는 경우가 많으므로, 미세한 기울기를 보정하기 위해서는 OpenCV를 활용해야 한다. 이미지 내의 모든 텍스트 컨투어(Contour)를 검출하고 cv2.minAreaRect를 통해 각 텍스트 블록의 회전각을 계산한 후, 그 중간값(Median)만큼 이미지를 역회전시키는 방법이 가장 신뢰할 수 있다. 1  
Dewarping (왜곡 보정):  
두꺼운 책을 펼쳐서 스캔할 때 발생하는 페이지의 굴곡은 텍스트 라인을 곡선으로 만든다. 이는 일반적인 회전 변환으로는 해결할 수 없다. 11에서는 3차원 모델링을 이용한 페이지 평탄화(Unprojecting text) 기법을 소개하고 있다. 이는 이미지 상의 텍스트 라인을 추적하여 그리드 모델을 만들고, 이를 평면으로 펴는 복잡한 알고리즘을 수반한다. 최근에는 딥러닝 기반의 문서 평탄화 모델(DocTr 등)이 이러한 전처리 과정을 자동화해주기도 한다.

## ---

**3\. 테서렉트 엔진 아키텍처와 파라미터 튜닝**

전처리가 '입력'을 다듬는 과정이라면, 파라미터 튜닝은 '엔진'이 그 입력을 어떻게 해석할지 지시하는 과정이다. 테서렉트 5.x 버전은 하이브리드 아키텍처를 가지고 있으며, 이를 이해하고 적절히 제어하는 것이 인식률 최적화의 핵심이다.

### **3.1 OCR 엔진 모드 (OEM): LSTM의 우월성**

OEM(OCR Engine Mode)은 테서렉트 내부의 어떤 인식 알고리즘을 사용할지 결정한다.

* **OEM 0 (Legacy Only):** 테서렉트 3.x 버전까지 사용되던 전통적인 엔진이다. 글자를 개별적으로 인식하고 패턴 매칭을 수행한다. 매우 깨끗한 기계 인쇄물에서는 효과적일 수 있으나, 문맥 정보를 활용하지 못해 노이즈에 취약하다.  
* **OEM 1 (Neural nets LSTM Only):** 테서렉트 4.0부터 도입된 딥러닝 기반 엔진이다. 입력 이미지를 픽셀 열(Slice)의 시퀀스로 취급하고, LSTM(Long Short-Term Memory) 네트워크를 통과시켜 텍스트 시퀀스를 예측한다. CTC(Connectionist Temporal Classification) 손실 함수를 사용하여 학습되었으며, 문맥 정보를 활용하기 때문에 획이 일부 손상되거나 변형된 글자도 앞뒤 글자를 통해 유추해낼 수 있다. 한국어와 같이 복잡한 문자의 인식률은 레거시 엔진 대비 압도적으로 높다. 2  
* **OEM 2 (Legacy \+ LSTM):** 두 엔진을 모두 사용하고 결과를 병합한다. 속도가 느려 실무에서는 잘 사용되지 않는다.  
* **OEM 3 (Default):** 데이터 파일(traineddata)의 구성에 따라 최적의 모드를 자동 선택한다. 최신 데이터 파일은 대부분 LSTM 전용이므로 OEM 1과 동일하게 작동한다.

**결론:** 한국어 인식률 최적화를 위해서는 **OEM 1**을 강제하거나, 최신 LSTM 모델을 사용하여 OEM 3을 유지하는 것이 정답이다.

### **3.2 페이지 세그멘테이션 모드 (PSM) 전략**

PSM(Page Segmentation Mode)은 테서렉트가 이미지 전체를 어떻게 분석하고 쪼갤지를 결정하는 옵션이다. 많은 사용자가 이 옵션을 간과하지만, 문서의 레이아웃에 맞지 않는 PSM을 사용하면 인식률이 0%가 될 수도 있다. 11

| PSM 모드 | 설명 및 한국어 적용 시나리오 |
| :---- | :---- |
| **PSM 3 (Auto)** | 기본값. 완전 자동 페이지 분할. 문단, 제목, 이미지를 자동으로 구분한다. 일반적인 A4 문서 스캔본에 적합하다. 하지만 표나 다단 편집 문서에서는 읽는 순서가 뒤섞일 수 있다. |
| **PSM 4 (Single Column)** | 텍스트가 하나의 열(Column)로 이루어져 있다고 가정한다. 영수증, 쇼핑 목록과 같이 세로로 긴 이미지에 효과적이다. 크기가 다른 폰트가 섞여 있어도 잘 처리한다. |
| **PSM 6 (Single Block)** | 이미지를 하나의 텍스트 블록으로 가정한다. 이미 전처리를 통해 텍스트 영역(ROI)을 잘라낸(Cropped) 이미지라면 PSM 3보다 훨씬 높은 정확도를 보인다. OSD(방향 탐지)나 레이아웃 분석을 생략하기 때문이다. |
| **PSM 7 (Single Line)** | 이미지가 단 한 줄의 텍스트만 포함한다고 가정한다. 딥러닝 기반의 텍스트 검출기(CRAFT, DBNet 등)를 사용하여 문장 단위로 이미지를 자른 후 테서렉트에 입력할 때 사용하는 최적의 모드이다. |
| **PSM 11 (Sparse Text)** | 텍스트가 불규칙하게 흩어져 있는 경우(예: 지도상의 지명, 도표 내 텍스트, 화이트보드 낙서)에 유용하다. 순서에 상관없이 최대한 많은 텍스트를 찾아낸다. 14의 사례에서 PSM 11은 엉뚱하게 결합되는 문장 오류를 해결하는 데 기여했다. |

수직 쓰기(Vertical Text) 대응:  
한국의 고문서나 현판, 일부 간판 등은 세로쓰기(Vertical writing)로 되어 있다. 이 경우 일반적인 한국어 모델(kor)을 사용하면 글자를 전혀 인식하지 못하거나 깨진 문자로 출력된다. 반드시 kor\_vert 모델을 다운로드하여 사용해야 하며, 동시에 PSM 5 (세로 정렬된 텍스트 블록 가정) 또는 PSM 9를 적용해야 한다. 15

### **3.3 화이트리스트 및 블랙리스트를 통한 검색 공간 축소**

OCR 엔진이 탐색해야 할 문자 공간(Search Space)을 줄여주는 것은 인식률을 높이는 가장 확실한 힌트(Hint)를 주는 셈이다.

* **화이트리스트 (tessedit\_char\_whitelist):** 인식할 문자 집합을 명시적으로 제한한다. 예를 들어, 전화번호부 이미지라면 숫자와 하이픈(0123456789-)만 화이트리스트에 등록함으로써, 숫자 '0'을 영문 'O'나 한글 'ㅇ'으로 오인식할 가능성을 원천 차단할 수 있다. 18  
* **블랙리스트 (tessedit\_char\_blacklist):** 결과에 절대 포함되지 말아야 할 문자를 지정한다. 특수문자나 OCR이 자주 헷갈려하는 노이즈 문자(예: |, \~, \`)를 등록하여 결과의 깔끔함을 유지할 수 있다.

## ---

**4\. 데이터 계층: 모델 선택과 관리 (Tessdata Variants)**

테서렉트의 성능은 사용하는 .traineddata 모델 파일의 품질에 달려 있다. 구글은 깃허브 저장소를 통해 세 가지 유형의 모델을 배포하고 있으며, 사용 환경과 목적에 따라 전략적으로 선택해야 한다. 19

### **4.1 모델 유형별 비교 분석**

1. **tessdata\_best (권장):**  
   * **특징:** 부동소수점(Float) 연산을 기반으로 학습된 가장 정밀한 모델이다. 네트워크의 레이어가 깊고 파라미터가 많아 용량이 크다.  
   * **장점:** 인식 정확도가 가장 높다. 특히 한국어와 같이 획이 복잡한 문자 인식에 유리하다. **파인튜닝(Fine-tuning)을 수행할 때 반드시 베이스 모델로 사용해야 한다.** 20  
   * **단점:** 속도가 느리다. 서버급 하드웨어가 아닌 경우 처리 시간이 부담될 수 있다.  
2. **tessdata\_fast:**  
   * **특징:** best 모델을 정수(Integer) 연산으로 양자화(Quantization)하고 네트워크 구조를 경량화한 모델이다.  
   * **장점:** 속도가 매우 빠르고 용량이 작아 모바일 기기나 임베디드 시스템, 실시간 처리가 필요한 환경에 적합하다. 리눅스 배포판(Ubuntu 등)의 tesseract-ocr 패키지를 설치할 때 기본으로 깔리는 모델이 이것이다. 22  
   * **단점:** 정확도가 떨어진다. 특히 해상도가 낮거나 노이즈가 있는 이미지에서 best 모델 대비 인식 실패율이 높다. 23  
3. **tessdata (Standard):**  
   * **특징:** 레거시 엔진과 LSTM 엔진 데이터를 모두 포함하거나, 그 중간 단계의 모델이다. 호환성을 위해 존재하지만, 성능 최적화를 위해서는 best나 fast 중 하나를 명확히 선택하는 것이 좋다.

최적의 전략:  
PC나 서버 환경에서 한국어 인식률을 최우선으로 한다면, 기본 설치된 모델을 믿지 말고 반드시 tessdata\_best 저장소에서 kor.traineddata를 직접 다운로드하여 교체해야 한다. 23의 논의에서도 알 수 있듯, best 모델은 처리 시간을 희생하더라도 결과의 품질을 보장한다.

### **4.2 스크립트 vs 언어 모델**

테서렉트는 언어별 모델(kor) 외에도 스크립트별 모델(script/Hangul)을 제공한다.

* kor.traineddata: 한국어 문장 데이터로 학습되어 언어적 통계(자주 쓰이는 단어 조합 등)가 반영된 모델이다. 일반적인 한국어 문장 인식에 적합하다.  
* script/Hangul.traineddata: 언어적 문맥보다는 '한글'이라는 글자 자체의 형상을 학습한 모델이다. 문장이 아닌 무작위 단어 나열이나, 특수한 용어, 혹은 한국어와 영어가 혼재되지 않은 순수 한글 인식에 더 유리할 수 있다.

## ---

**5\. 파인튜닝(Fine-tuning): 한국어 인식률의 퀀텀 점프**

기본 제공되는 구글의 kor.traineddata는 수많은 폰트와 문서를 학습한 범용 모델이다. 그러나 범용성이라는 것은 역설적으로 특정 도메인(예: 의료 처방전, 법원 판결문, 특이한 손글씨체 등)에서는 최적의 성능을 내지 못한다는 것을 의미한다. 인식률을 95% 이상, 99% 수준으로 끌어올리기 위한 '성배(Holy Grail)'는 바로 사용자 데이터에 맞춘 **파인튜닝**이다. 25

### **5.1 파인튜닝의 이론적 배경: 전이 학습(Transfer Learning)**

테서렉트 5의 LSTM 엔진 훈련은 전이 학습 원리를 따른다. 처음부터 모든 한글 11,172자를 학습시키는 것(Scratch Training)은 엄청난 데이터와 시간을 요구하며 수렴하기도 어렵다. 대신, 이미 한글의 기본적인 형상과 특징을 알고 있는 tessdata\_best/kor.traineddata 모델의 가중치(Weight)를 초기값으로 두고, 사용자가 원하는 특정 폰트나 문서 스타일의 데이터를 추가로 학습시켜 모델을 미세 조정(Fine-tuning)하는 방식이 훨씬 효율적이다. 이 방식은 적은 양의 데이터로도 극적인 성능 향상을 가져온다. 28

### **5.2 데이터 준비 및 학습 워크플로우 (Tesstrain)**

과거에는 쉘 스크립트 등을 이용해 복잡하게 학습을 수행했으나, 현재는 tesstrain 리포지토리의 Makefile을 사용하는 것이 표준이다. 30

Step 1: 학습 데이터 생성 (Ground Truth)  
파인튜닝을 위해서는 '이미지'와 그 이미지에 적힌 '정답 텍스트' 쌍이 필요하다.

1. **실제 데이터 활용:** 실제 인식 대상이 될 문서 이미지들을 확보하고, 이를 한 줄(Line) 단위로 자른 뒤, 텍스트 파일에 정답을 입력한다. (.tif 또는 .png 이미지와 동일한 이름의 .gt.txt 파일 생성)  
2. **합성 데이터 활용:** text2image 도구를 사용하여 특정 폰트로 텍스트 이미지를 자동 생성할 수 있다. 31 이 때, 한국어의 모든 글자를 학습시키기 위해 2,350자(KS X 1001 상용 한글) 리스트나 11,172자 리스트를 활용해야 한다. 32

Step 2: 초기 모델 및 환경 설정  
tesstrain 폴더 내에 data/모델명-ground-truth 디렉토리를 만들고 준비한 데이터 쌍을 넣는다. 그리고 tessdata\_best/kor.traineddata를 다운로드하여 시작 모델로 지정한다.  
Step 3: 학습 실행 (make training)  
터미널에서 다음과 같은 명령어로 학습을 시작한다. 30

Bash

make training MODEL\_NAME=my\_korean\_model START\_MODEL=kor TESSDATA=../tessdata\_best MAX\_ITERATIONS=10000

* MODEL\_NAME: 새로 만들 모델의 이름.  
* START\_MODEL: 베이스가 될 모델 (반드시 best 버전이어야 함).  
* MAX\_ITERATIONS: 반복 횟수. 한국어는 클래스 수가 많으므로 충분한 반복이 필요하나, 과적합(Overfitting)을 주의해야 한다. BCER(Best Character Error Rate)이 더 이상 떨어지지 않는 지점에서 멈추는 것이 좋다.

Step 4: 인코딩 오류 해결 및 Unicharset 병합  
한국어 파인튜닝 시 가장 흔히 겪는 문제는 "Encoding of string failed\!" 오류이다. 34 이는 학습 데이터에 포함된 글자(예: 믜, 갋 등 희귀 한글)가 기존 kor.traineddata의 문자 집합(Unicharset)에 없을 때 발생한다. 이를 해결하기 위해서는 학습 데이터에서 새로운 Unicharset을 추출하고, 이를 기존 모델의 Unicharset과 병합(Merge)하여 새로운 .traineddata를 생성하는 과정을 거쳐야 한다. 34의 tess4korean 스크립트는 이 과정을 자동화하는 좋은 참조 모델이다.

## ---

**6\. 후처리(Post-processing): 자연어 처리를 통한 보정**

OCR 엔진이 뱉어낸 결과물은 최종 결과물이 아니다. 특히 한국어는 자소 결합의 특성상 기계적인 오류가 발생하기 쉽다. 후처리는 이러한 오류를 언어적 지식과 알고리즘으로 보정하여 '사람이 읽을 수 있는' 텍스트로 완성하는 단계이다.

### **6.1 자소 결합 및 분리 오류 수정 (Jamo Recomposition)**

테서렉트가 한국어 글자를 인식할 때, 간혹 완성된 글자가 아닌 자음과 모음을 개별적으로 인식하는 경우가 있다 (예: '학교' \-\> 'ㅎㅏㄱ교'). 이는 유니코드 정규화(Normalization) 이슈이거나, 폰트의 자소 간 간격이 넓어 발생한다. 35

이를 해결하기 위해 Python의 hgtk 또는 jamotools 라이브러리를 사용한다. 이 라이브러리들은 분리된 자소를 다시 하나의 음절로 합쳐준다. 37

* **원리:** 텍스트 스트림을 스캔하여 초성+중성(+종성)의 패턴이 발견되면 이를 즉시 하나의 유니코드 글자로 합친다.  
* **코드 예시:** hgtk.text.compose('ㅎㅏㄱ교') \-\> '학교'  
* 이 과정에서 한글 구성 원리에 맞지 않는 자소 조합(예: 초성 없이 중성만 오는 경우 등)을 필터링하여 노이즈를 제거할 수도 있다.

### **6.2 맞춤법 검사 및 교정 (Spell Checking)**

오인식된 글자를 문맥에 맞는 단어로 교정하기 위해 맞춤법 검사기나 유사도 기반의 교정 알고리즘을 사용한다.

* **SymSpell:** 전통적인 사전 기반 교정 방식보다 월등히 빠른 속도를 자랑한다. 편집 거리(Edit Distance) 알고리즘을 사용하여, 오타가 발생한 단어와 사전에 있는 단어 간의 거리를 계산해 교정한다. 한국어의 경우 자소 단위로 분해하여 편집 거리를 계산하면('한'과 '힌'의 거리는 가깝다) 더욱 정교한 교정이 가능하다. 39  
* **Py-Hanspell:** 네이버 맞춤법 검사기를 파이썬 래퍼로 만든 라이브러리다. 단순 오타뿐만 아니라 문법적 오류와 띄어쓰기 오류를 동시에 잡아낸다. OCR 결과의 가독성을 높이는 데 매우 효과적이다. 41

### **6.3 띄어쓰기 교정 (PyKoSpacing)**

OCR 결과물에서 띄어쓰기가 무시되거나(모두 붙여 씀) 과도하게 들어가는(자소마다 띄어 씀) 경우가 많다. **PyKoSpacing**은 대용량 코퍼스로 학습된 딥러닝 모델을 사용하여 띄어쓰기가 없는 문장을 입력받아 문맥에 맞게 띄어쓰기를 수행한다. 43 이는 후속 자연어 처리(형태소 분석 등)를 위해 필수적인 단계이다.

### **6.4 LLM(Large Language Model) 기반 의미론적 보정**

최근에는 GPT-4, Claude 3와 같은 거대 언어 모델(LLM)을 후처리 도구로 활용하는 사례가 늘고 있다. 44

* **방법:** OCR의 원문 결과(Raw Text)를 LLM에 프롬프트로 제공하면서, "이 텍스트는 영수증이다. 오타를 수정하고 항목과 가격을 정리해라"와 같은 지시를 내린다.  
* **효과:** LLM은 '비용'을 '비응'으로, '합계'를 '합개'로 인식한 기계적 오류를 문맥(Context)을 통해 파악하고 수정한다. 이는 단순한 규칙 기반(Rule-based) 후처리가 해결하지 못하는 의미론적 오류를 잡는 데 강력하다.

## ---

**7\. 경쟁 엔진 비교 및 하이브리드 전략**

테서렉트는 강력하지만 만능은 아니다. 특히 복잡한 배경이나 비정형 텍스트(Scene Text) 인식에서는 최신 딥러닝 기반 엔진들에 비해 열세를 보인다.

### **7.1 Tesseract vs. PaddleOCR vs. EasyOCR 벤치마크**

| 특징 | 테서렉트 (Tesseract 5\) | PaddleOCR (PP-OCRv4) | EasyOCR |
| :---- | :---- | :---- | :---- |
| **아키텍처** | LSTM (Seq2Seq) | DBNet (검출) \+ CRNN (인식) | CRNN (VGG \+ LSTM \+ CTC) |
| **강점** | 스캔 문서(Document), 고해상도 인쇄물, 텍스트 밀도가 높은 문서 | **복잡한 배경, 자연 장면(Scene), 표/서식 인식, 한국어 모델 성능 압도적** | 사용 편의성, GPU 가속 지원, 파이썬 친화적 |
| **약점** | 노이즈에 취약, 기울어진 텍스트에 약함, 전처리 의존도 높음 | PaddlePaddle 프레임워크 의존성, 설정 다소 복잡 | 속도가 상대적으로 느릴 수 있음 |
| **한국어 성능** | 문서형 이미지에서 우수 (파인튜닝 시) | **비정형/야생(In-the-wild) 이미지에서 최고 성능** 45 | 준수한 성능, 간편한 도입 |

45 등의 최신 벤치마크 결과에 따르면, 문서 스캔이 아닌 카메라 촬영 이미지나 배경이 복잡한 이미지에서는 **PaddleOCR**이 테서렉트보다 월등한 한국어 인식률(95% 이상)을 보이는 것으로 나타났다. 특히 PaddleOCR의 PP-OCRv4 모델은 경량화되어 있으면서도 한국어 인식 정확도가 매우 높다.

### **7.2 최적의 하이브리드 파이프라인**

단일 엔진에 의존하기보다 각 엔진의 장점을 결합하는 것이 최상의 결과를 낳는다.

1. **텍스트 영역 검출(Detection):** 테서렉트의 자체 레이아웃 분석보다는 PaddleOCR의 DBNet이나 CRAFT와 같은 강력한 딥러닝 검출기를 사용하여 텍스트 영역(Bounding Box)을 먼저 정확히 잘라낸다.  
2. **텍스트 인식(Recognition):**  
   * 잘라낸 영역이 깔끔한 인쇄체 문서라면 \*\*Tesseract(Fine-tuned)\*\*를 사용한다. (세밀한 제어가 가능)  
   * 배경이 복잡하거나 디자인된 글자, 손글씨라면 **PaddleOCR**이나 **EasyOCR**을 사용한다.  
3. **앙상블(Ensemble):** 두 엔진의 결과를 모두 얻은 후, 신뢰도(Confidence Score)가 더 높은 결과를 채택하거나, 두 결과가 다를 경우 LLM에게 판단을 맡기는 방식으로 정확도를 극대화한다. 49

## ---

**8\. 결론: "최고의 방법"을 향한 실행 로드맵**

테서렉트 OCR의 한국어 인식률을 높이는 "단 하나의 마법 같은 버튼"은 존재하지 않는다. 최고의 성능은 고품질의 데이터 입력, 엔진의 정밀한 튜닝, 그리고 지능적인 후처리가 결합된 파이프라인에서 나온다. 본 보고서의 분석을 종합하여 다음과 같은 실행 로드맵을 제안한다.

1. **입력 최적화 (Input Optimization):**  
   * 이미지 해상도를 300 DPI 이상으로 리사이징하고, OpenCV의 적응형 임계값(Adaptive Thresholding)과 형태학적 연산을 적용하여 획을 보존하라.  
   * 자동 기울기 보정(Deskewing)을 전처리 파이프라인의 첫 단추로 끼워라.  
2. **엔진 고도화 (Engine Enhancement):**  
   * 반드시 **tessdata\_best** 모델을 사용하라.  
   * 문서의 레이아웃에 따라 **PSM 6** (단일 블록)이나 **PSM 4** (단일 열)를 전략적으로 선택하라.  
   * 대상 문서의 폰트와 스타일을 반영한 데이터셋을 구축하여 **tesstrain으로 파인튜닝**하라. 이것이 인식률 99%로 가는 가장 확실한 길이다.  
3. **지능형 후처리 (Intelligent Post-processing):**  
   * hgtk로 자소 분리 오류를 잡고, Py-Hanspell과 PyKoSpacing으로 문장 구조를 바로잡아라.  
   * 가능하다면 LLM을 도입하여 의미론적 교정을 수행하라.  
4. **유연한 전환 (Flexible Strategy):**  
   * 자연 장면 이미지나 손글씨 인식에서는 테서렉트를 고집하지 말고 **PaddleOCR**을 도입하여 하이브리드 시스템을 구축하라.

이러한 체계적이고 공학적인 접근을 통해, 난해한 한국어 OCR의 한계를 극복하고 상용 솔루션에 버금가는 강력한 인식 시스템을 구축할 수 있을 것이다.

#### **참고 자료**

1. Boost Tesseract OCR Accuracy: Advanced Tips & Techniques \- Sparkco, 1월 18, 2026에 액세스, [https://sparkco.ai/blog/boost-tesseract-ocr-accuracy-advanced-tips-techniques](https://sparkco.ai/blog/boost-tesseract-ocr-accuracy-advanced-tips-techniques)  
2. image processing to improve tesseract OCR accuracy \- Stack Overflow, 1월 18, 2026에 액세스, [https://stackoverflow.com/questions/9480013/image-processing-to-improve-tesseract-ocr-accuracy](https://stackoverflow.com/questions/9480013/image-processing-to-improve-tesseract-ocr-accuracy)  
3. An Effective OCR Approach Based on Gradual Detection of Texts \- MDPI, 1월 18, 2026에 액세스, [https://www.mdpi.com/2227-7390/11/22/4585](https://www.mdpi.com/2227-7390/11/22/4585)  
4. How to Apply OCR and Extract Text for the Image In Korean Language \- Stack Overflow, 1월 18, 2026에 액세스, [https://stackoverflow.com/questions/76279728/how-to-apply-ocr-and-extract-text-for-the-image-in-korean-language](https://stackoverflow.com/questions/76279728/how-to-apply-ocr-and-extract-text-for-the-image-in-korean-language)  
5. python \- How to improve the OCR accuracy in this image? \- Stack Overflow, 1월 18, 2026에 액세스, [https://stackoverflow.com/questions/67360958/how-to-improve-the-ocr-accuracy-in-this-image](https://stackoverflow.com/questions/67360958/how-to-improve-the-ocr-accuracy-in-this-image)  
6. Morphological Transformations \- OpenCV, 1월 18, 2026에 액세스, [https://docs.opencv.org/3.4/d4/d76/tutorial\_js\_morphological\_ops.html](https://docs.opencv.org/3.4/d4/d76/tutorial_js_morphological_ops.html)  
7. Morphological Transformations \- OpenCV, 1월 18, 2026에 액세스, [https://docs.opencv.org/4.x/d9/d61/tutorial\_py\_morphological\_ops.html](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html)  
8. OpenCV: Morphological Dilation and Erosion | by Sasani Perera | Medium, 1월 18, 2026에 액세스, [https://medium.com/@sasaniperera/opencv-morphological-dilation-and-erosion-fab65c29efb3](https://medium.com/@sasaniperera/opencv-morphological-dilation-and-erosion-fab65c29efb3)  
9. How to decide on the kernel to use for dilations (OpenCV/Python)? \- Stack Overflow, 1월 18, 2026에 액세스, [https://stackoverflow.com/questions/67117928/how-to-decide-on-the-kernel-to-use-for-dilations-opencv-python](https://stackoverflow.com/questions/67117928/how-to-decide-on-the-kernel-to-use-for-dilations-opencv-python)  
10. Looking for adaptive kernel size detector for dilate \- OpenCV Forum, 1월 18, 2026에 액세스, [https://forum.opencv.org/t/looking-for-adaptive-kernel-size-detector-for-dilate/5794](https://forum.opencv.org/t/looking-for-adaptive-kernel-size-detector-for-dilate/5794)  
11. Improving the quality of the output | tessdoc \- Tesseract documentation, 1월 18, 2026에 액세스, [https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html](https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html)  
12. tesseract/doc/tesseract.1.asc at main · tesseract-ocr/tesseract \- GitHub, 1월 18, 2026에 액세스, [https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc](https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc)  
13. All Tesseract OCR options \- Muthukrishnan, 1월 18, 2026에 액세스, [https://muthu.co/all-tesseract-ocr-options/](https://muthu.co/all-tesseract-ocr-options/)  
14. Tesseract v4 generated incorrect text output \- Google Groups, 1월 18, 2026에 액세스, [https://groups.google.com/g/tesseract-ocr/c/o5DmYn836-8/m/GmbhzugWCwAJ](https://groups.google.com/g/tesseract-ocr/c/o5DmYn836-8/m/GmbhzugWCwAJ)  
15. Debian \-- Details of package tesseract-ocr-kor-vert in sid, 1월 18, 2026에 액세스, [https://packages.debian.org/sid/tesseract-ocr-kor-vert](https://packages.debian.org/sid/tesseract-ocr-kor-vert)  
16. tesseract \- command-line OCR engine \- Ubuntu Manpage, 1월 18, 2026에 액세스, [https://manpages.ubuntu.com/manpages/focal/man1/tesseract.1.html](https://manpages.ubuntu.com/manpages/focal/man1/tesseract.1.html)  
17. kor\_vert.traineddata \- tesseract-ocr/tessdata\_best \- GitHub, 1월 18, 2026에 액세스, [https://github.com/tesseract-ocr/tessdata\_best/blob/main/kor\_vert.traineddata](https://github.com/tesseract-ocr/tessdata_best/blob/main/kor_vert.traineddata)  
18. tessl/npm-tesseract-js@6.0.x \- Registry, 1월 18, 2026에 액세스, [https://tessl.io/registry/tessl/npm-tesseract-js/6.0.0/files/docs/configuration-constants.md](https://tessl.io/registry/tessl/npm-tesseract-js/6.0.0/files/docs/configuration-constants.md)  
19. Traineddata Files for Version 4.00 \+ | tessdoc \- Tesseract documentation, 1월 18, 2026에 액세스, [https://tesseract-ocr.github.io/tessdoc/Data-Files.html](https://tesseract-ocr.github.io/tessdoc/Data-Files.html)  
20. kor.traineddata \- tesseract-ocr/tessdata \- GitHub, 1월 18, 2026에 액세스, [https://github.com/tesseract-ocr/tessdata/blob/main/kor.traineddata](https://github.com/tesseract-ocr/tessdata/blob/main/kor.traineddata)  
21. tesseract-ocr/tessdata\_best: Best (most accurate) trained LSTM models. \- GitHub, 1월 18, 2026에 액세스, [https://github.com/tesseract-ocr/tessdata\_best](https://github.com/tesseract-ocr/tessdata_best)  
22. RPM resource tesseract-ocr-traineddata-kor\_vert \- Rpmfind.net, 1월 18, 2026에 액세스, [https://www.rpmfind.net/linux/rpm2html/search.php?query=tesseract-ocr-traineddata-kor\_vert](https://www.rpmfind.net/linux/rpm2html/search.php?query=tesseract-ocr-traineddata-kor_vert)  
23. tessdata "fast" vs "best" · Issue \#52 · OCR-D/ocrd\_all \- GitHub, 1월 18, 2026에 액세스, [https://github.com/OCR-D/ocrd\_all/issues/52](https://github.com/OCR-D/ocrd_all/issues/52)  
24. Settle on Tesseract model type · Issue \#545 · freedomofpress/dangerzone \- GitHub, 1월 18, 2026에 액세스, [https://github.com/freedomofpress/dangerzone/issues/545](https://github.com/freedomofpress/dangerzone/issues/545)  
25. creating train data set for Korean \- Google Groups, 1월 18, 2026에 액세스, [https://groups.google.com/g/tesseract-ocr/c/U6rGP4LVcC8](https://groups.google.com/g/tesseract-ocr/c/U6rGP4LVcC8)  
26. Tesseract for License Plate (especially Korean version) \- Stack Overflow, 1월 18, 2026에 액세스, [https://stackoverflow.com/questions/59558820/tesseract-for-license-plate-especially-korean-version](https://stackoverflow.com/questions/59558820/tesseract-for-license-plate-especially-korean-version)  
27. tessdoc/tess5/TrainingTesseract-5.md at main \- GitHub, 1월 18, 2026에 액세스, [https://github.com/tesseract-ocr/tessdoc/blob/main/tess5/TrainingTesseract-5.md](https://github.com/tesseract-ocr/tessdoc/blob/main/tess5/TrainingTesseract-5.md)  
28. Improving the Accuracy of Tesseract 4.0 OCR Engine Using Convolution-Based Preprocessing \- MDPI, 1월 18, 2026에 액세스, [https://www.mdpi.com/2073-8994/12/5/715](https://www.mdpi.com/2073-8994/12/5/715)  
29. Fine-tuning Tesseract's OCR (with some help from R) \- Andrés Cruz, 1월 18, 2026에 액세스, [https://andrescruz.org/posts/finetuning-tess/](https://andrescruz.org/posts/finetuning-tess/)  
30. tesseract-ocr/tesstrain: Train Tesseract LSTM with make \- GitHub, 1월 18, 2026에 액세스, [https://github.com/tesseract-ocr/tesstrain](https://github.com/tesseract-ocr/tesstrain)  
31. Tesseract training \- text2image returning Segmentation Fault every time on Ubuntu, 1월 18, 2026에 액세스, [https://stackoverflow.com/questions/38771327/tesseract-training-text2image-returning-segmentation-fault-every-time-on-ubunt](https://stackoverflow.com/questions/38771327/tesseract-training-text2image-returning-segmentation-fault-every-time-on-ubunt)  
32. IBM/tensorflow-hangul-recognition: Handwritten Korean Character Recognition with TensorFlow and Android \- GitHub, 1월 18, 2026에 액세스, [https://github.com/IBM/tensorflow-hangul-recognition](https://github.com/IBM/tensorflow-hangul-recognition)  
33. The Adobe-KR-9 Character Collection \- GitHub, 1월 18, 2026에 액세스, [https://github.com/adobe-type-tools/Adobe-KR](https://github.com/adobe-type-tools/Adobe-KR)  
34. whoareyouwhoami/tess4korean: Tesseract Training for ... \- GitHub, 1월 18, 2026에 액세스, [https://github.com/whoareyouwhoami/tess4korean](https://github.com/whoareyouwhoami/tess4korean)  
35. Korean Characters Appear Separated (Jamo Not Composing into Syllables) · Issue \#488 · amantus-ai/vibetunnel \- GitHub, 1월 18, 2026에 액세스, [https://github.com/amantus-ai/vibetunnel/issues/488](https://github.com/amantus-ai/vibetunnel/issues/488)  
36. Hangul Jamo sequences that describe a Modern Hangul syllable not displaying correctly on Microsoft Word · Issue \#306 · notofonts/noto-cjk \- GitHub, 1월 18, 2026에 액세스, [https://github.com/notofonts/noto-cjk/issues/306](https://github.com/notofonts/noto-cjk/issues/306)  
37. JDongian/python-jamo: Hangul syllable decomposition and synthesis using jamo. \- GitHub, 1월 18, 2026에 액세스, [https://github.com/JDongian/python-jamo](https://github.com/JDongian/python-jamo)  
38. jamo \- PyPI, 1월 18, 2026에 액세스, [https://pypi.org/project/jamo/](https://pypi.org/project/jamo/)  
39. Improving Tesseract OCR Accuracy Using SymSpell Algorithm on Passport Data, 1월 18, 2026에 액세스, [https://jurnal.polgan.ac.id/index.php/sinkron/article/download/14395/3059/21371](https://jurnal.polgan.ac.id/index.php/sinkron/article/download/14395/3059/21371)  
40. Korean spelling correction: Symspell을 이용한 한글 맞춤법 교정 \- SeekStorm, 1월 18, 2026에 액세스, [https://seekstorm.com/blog/korean-spelling-correction-with-symspell/](https://seekstorm.com/blog/korean-spelling-correction-with-symspell/)  
41. Treating OCR Output as a Language (TOOL) – Improving OCR Output with Seq2Seq Translation \- Annals of Computer Science and Information Systems, 1월 18, 2026에 액세스, [https://annals-csis.org/proceedings/2025/pliks/1103.pdf](https://annals-csis.org/proceedings/2025/pliks/1103.pdf)  
42. OCR spelling correction is hard \- Max Halford, 1월 18, 2026에 액세스, [https://maxhalford.github.io/blog/ocr-spelling-correction-is-hard/](https://maxhalford.github.io/blog/ocr-spelling-correction-is-hard/)  
43. haven-jeon/PyKoSpacing: Automatic Korean word spacing with Python \- GitHub, 1월 18, 2026에 액세스, [https://github.com/haven-jeon/PyKoSpacing](https://github.com/haven-jeon/PyKoSpacing)  
44. LLM Aided OCR (Correcting Tesseract OCR Errors with LLMs with Python) \- Reddit, 1월 18, 2026에 액세스, [https://www.reddit.com/r/Python/comments/1eo6dxz/llm\_aided\_ocr\_correcting\_tesseract\_ocr\_errors/](https://www.reddit.com/r/Python/comments/1eo6dxz/llm_aided_ocr_correcting_tesseract_ocr_errors/)  
45. OCR engine：substitute PaddleOCR for Tesseract-OCR · Issue \#10232 · siyuan-note/siyuan, 1월 18, 2026에 액세스, [https://github.com/siyuan-note/siyuan/issues/10232](https://github.com/siyuan-note/siyuan/issues/10232)  
46. What Makes OCR Different in 2025? Impact of Multimodal LLMs and AI Trends \- Photes.io, 1월 18, 2026에 액세스, [https://photes.io/blog/posts/ocr-research-trend](https://photes.io/blog/posts/ocr-research-trend)  
47. Evaluating OCR performance on food packaging labels in South Africa \- arXiv, 1월 18, 2026에 액세스, [https://arxiv.org/html/2510.03570v1](https://arxiv.org/html/2510.03570v1)  
48. (PDF) KORIE: A Multi-Task Benchmark for Detection, OCR, and Information Extraction on Korean Retail Receipts \- ResearchGate, 1월 18, 2026에 액세스, [https://www.researchgate.net/publication/399461872\_KORIE\_A\_Multi-Task\_Benchmark\_for\_Detection\_OCR\_and\_Information\_Extraction\_on\_Korean\_Retail\_Receipts](https://www.researchgate.net/publication/399461872_KORIE_A_Multi-Task_Benchmark_for_Detection_OCR_and_Information_Extraction_on_Korean_Retail_Receipts)  
49. How to Convert Image to Text Using Python: A Comprehensive Guide for 2024 \- Affinda AI, 1월 18, 2026에 액세스, [https://www.affinda.com/blog/how-to-convert-image-to-text-using-python](https://www.affinda.com/blog/how-to-convert-image-to-text-using-python)